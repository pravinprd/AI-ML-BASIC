{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.chunk import ne_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"Hello there, how are you? Weather is awesome....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Hello Mr. Raja, how are you? Weather is aweso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"Hello Mr. Raja, how are you. Weather is bad. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"NLP is great technique. It is nice to learn t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"AI is making difference in this world now.  I...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Comment\n",
       "0  \"Hello there, how are you? Weather is awesome....\n",
       "1  \"Hello Mr. Raja, how are you? Weather is aweso...\n",
       "2  \"Hello Mr. Raja, how are you. Weather is bad. ...\n",
       "3  \"NLP is great technique. It is nice to learn t...\n",
       "4  \"AI is making difference in this world now.  I..."
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data_in_token.csv',sep=',',index_col=None)\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenised Sentences:[{'Comment': '\"Hello there, how are you?'}, {'Comment': 'Weather is awesome.'}, {'Comment': 'Its raining here now.\"'}, {'Comment': '\"Hello Mr. Raja, how are you?'}, {'Comment': 'Weather is awesome.'}, {'Comment': 'Its raining here now.\"'}, {'Comment': '\"Hello Mr. Raja, how are you.'}, {'Comment': 'Weather is bad.'}, {'Comment': 'Its heavily raining here now.\"'}, {'Comment': '\"NLP is great technique.'}, {'Comment': 'It is nice to learn this technique.\"'}, {'Comment': '\"AI is making difference in this world now.'}, {'Comment': 'It would be helpful for betterment of human life.'}, {'Comment': 'We need to make advantage of that.\"'}]\n"
     ]
    }
   ],
   "source": [
    "lst=[]\n",
    "for sentence in data['Comment'] :\n",
    " tokens=sent_tokenize(sentence)\n",
    " for each in tokens:\n",
    "  dict['Comment']=each\n",
    "  lst.append(dict)\n",
    "  dict={}\n",
    "output=pd.DataFrame(lst)\n",
    "output.to_csv(\"data_out_sentence.csv\")\n",
    "print(\"Tokenised Sentences:{0}\".format(lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 1\n",
      "(S ``/`` Hello/NNP there/RB ,/, how/WRB are/VBP you/PRP ?/.)\n",
      "Sentence 2\n",
      "(S (GPE Weather/NNP) is/VBZ awesome/JJ ./.)\n",
      "Sentence 3\n",
      "(S Its/PRP$ raining/VBG here/RB now/RB ./. ''/'')\n",
      "Sentence 4\n",
      "(S\n",
      "  ``/``\n",
      "  (PERSON Hello/NNP Mr./NNP Raja/NNP)\n",
      "  ,/,\n",
      "  how/WRB\n",
      "  are/VBP\n",
      "  you/PRP\n",
      "  ?/.)\n",
      "Sentence 5\n",
      "(S (GPE Weather/NNP) is/VBZ awesome/JJ ./.)\n",
      "Sentence 6\n",
      "(S Its/PRP$ raining/VBG here/RB now/RB ./. ''/'')\n",
      "Sentence 7\n",
      "(S\n",
      "  ``/``\n",
      "  (PERSON Hello/NNP Mr./NNP Raja/NNP)\n",
      "  ,/,\n",
      "  how/WRB\n",
      "  are/VBP\n",
      "  you/PRP\n",
      "  ./.)\n",
      "Sentence 8\n",
      "(S (GPE Weather/NNP) is/VBZ bad/JJ ./.)\n",
      "Sentence 9\n",
      "(S Its/PRP$ heavily/RB raining/VBG here/RB now/RB ./. ''/'')\n",
      "Sentence 10\n",
      "(S ``/`` (ORGANIZATION NLP/NNP) is/VBZ great/JJ technique/NN ./.)\n",
      "Sentence 11\n",
      "(S\n",
      "  It/PRP\n",
      "  is/VBZ\n",
      "  nice/JJ\n",
      "  to/TO\n",
      "  learn/VB\n",
      "  this/DT\n",
      "  technique/NN\n",
      "  ./.\n",
      "  ''/'')\n",
      "Sentence 12\n",
      "(S\n",
      "  ``/``\n",
      "  AI/NNP\n",
      "  is/VBZ\n",
      "  making/VBG\n",
      "  difference/NN\n",
      "  in/IN\n",
      "  this/DT\n",
      "  world/NN\n",
      "  now/RB\n",
      "  ./.)\n",
      "Sentence 13\n",
      "(S\n",
      "  It/PRP\n",
      "  would/MD\n",
      "  be/VB\n",
      "  helpful/JJ\n",
      "  for/IN\n",
      "  betterment/NN\n",
      "  of/IN\n",
      "  human/JJ\n",
      "  life/NN\n",
      "  ./.)\n",
      "Sentence 14\n",
      "(S\n",
      "  We/PRP\n",
      "  need/VBP\n",
      "  to/TO\n",
      "  make/VB\n",
      "  advantage/NN\n",
      "  of/IN\n",
      "  that/DT\n",
      "  ./.\n",
      "  ''/'')\n"
     ]
    }
   ],
   "source": [
    "tokenised_sentence=pd.read_csv('data_out_sentence.csv',sep=',',index_col=None)\n",
    "i=0\n",
    "for sent in tokenised_sentence['Comment']:\n",
    " chunk_sentence = ne_chunk(pos_tag(word_tokenize(sent)))\n",
    " i=i+1\n",
    " print(\"Sentence {0}\".format(i))\n",
    " print (chunk_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
